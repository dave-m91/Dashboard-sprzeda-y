from calendar import week
import stat
import pandas as pd
from sklearn.linear_model import LinearRegression
import numpy as np


class TrendPredictor:
    def __init__(self, data: pd.DataFrame):
        """Inicjalizacja danych"""
        self.data = data
        self.model = LinearRegression()

    def prepare_series(self, index_id: str):
        """Przygotowanie danych"""
        mask = self.data["index_id"] == index_id
        temp_df = self.data[mask].copy()

        if temp_df.empty:
            print(f"Brak danych dla indeksu: {index_id}")
            return None
        
        temp_df = temp_df.set_index("date")
        #Agregacja tygodni
        weekly_series = temp_df["sales"].resample("W").sum()
        # Uzupenienie luk w przypadku braku sprzeda偶y
        weekly_series = weekly_series.asfreq("W", fill_value=0)
        return weekly_series

    def get_trend_metrics(self, series: pd.Series):
        """Regresja liniowa i R2"""
        y = series.values
        X = np.arange(len(y)).reshape(-1,1)
        self.model.fit(X, y)

        slope = self.model.coef_[0] # nachylenie z funkcji liniowej
        r2 = self.model.score(X, y)

        return {
            "slope": slope,
            "r2": r2,
            "intercept": self.model.intercept_
        }

    def predict_future(self, series: pd.Series, steps: int=4):
        """Prognoza na iloc krok贸w w prz贸d"""
        y = series.values
        X = np.arange(len(y)).reshape(-1,1)

        self.model.fit(X, y)
        last_x= X[-1,0]
        feature_X = np.arange(last_x + 1, last_x + 1 + steps).reshape(-1,1)

        forecast_values = self.model.predict(feature_X)
        forecast_values = np.maximum(forecast_values, 0)

        last_date = series.index[-1]
        feature_dates = pd.date_range(start=last_date, periods = steps+1, freq="W")[1:]

        return pd.DataFrame({
            "date": feature_dates,
            "predicted_sales": forecast_values
        }).set_index("date")

    def analyze_current_state(self, series: pd.Series, window: int=4):
        """Analiza dynamiki:
            Por贸wnanie redniej sprzeda偶y z ostatniego okna
            do redniej z poprzedniego okna"""
        if len(series) < window *2:
            return {"status": "Nieznany (za mao danych)",
                    "velocity": 0.0, "current_avg":0.0, "previous_avg":0.0}
        
        # Podzia na obecne i poprzednie
        current_period = series.iloc[-window:]
        previous_period = series.iloc[-2*window : -window]

        # rednie
        curr_mean = current_period.mean()
        prev_mean = previous_period.mean()

        # Oblicznie % zmiany
        if prev_mean == 0:
            velocity = 1.0 if curr_mean > 0 else 0.0
        else:
            velocity = (curr_mean - prev_mean) / prev_mean

        if velocity > 0.10:
            status = "Wzrost"
        elif velocity < -0.10:
            status = "Spadek"
        else:
            status = "Stablinie"

        return {
            "status": status,
            "velocity": velocity,
            "current_avg": curr_mean,
            "previous_avg": prev_mean
        }

    def calculate_slope(self, series: pd.Series):
        """
        Oblicza przypiesznie trendu
        """
        n = len(series)
        if n < 8: # minimum danych
            return "Za mao danych"
        
        mid_point = n // 2

        # Nachylenie pierwszej poowy
        metrics_past = self.get_trend_metrics(series.iloc[:mid_point])
        slope_past = metrics_past["slope"]

        # Nachylenie drugiej poowy
        metrics_now = self.get_trend_metrics(series[mid_point:])
        slope_now = metrics_now["slope"]

        diff = slope_now - slope_past

        if diff > 0.05: return "Przypiesza"
        if diff < -0.05: return "Zwalnia"
        return "Stae tempo"
    
    def generate_batch_ranking(self, min_sales_treshold: int =10):
        """
        Przetwarza uniklane produkty, generujc tabel KPI
        """
        unique_ids = self.data["index_id"].unique()
        results = []

        for index_id in unique_ids:
            series = self.prepare_series(index_id)

            if series is None or series.sum() < min_sales_treshold:
                continue
            
            try:
                metrics = self.get_trend_metrics(series)
                state = self.analyze_current_state(series)
                momentum = self.calculate_slope(series)

                results.append({
                    "index_id": index_id,
                    "total_sales": series.sum(),
                    "last_sales": series.iloc[-1],
                    "slope": round(metrics["slope"],3),
                    "velocity_pct": round(state["velocity"],3),
                    "trend_status": momentum,
                    "r2": round(metrics["r2"],2)
                })
            except Exception as e:
                continue

        ranking_df = pd.DataFrame(results)

        if not ranking_df.empty:
            ranking_df = ranking_df.sort_values(by="velocity_pct", ascending=False)
        return ranking_df

    def generate_batch_ranking_fast(self, windows_week: int=12, min_sales: int=10, min_active_weeks: int=4):
        """
        Przypieszona wersja rankingu, wykorzystujca wektoryzacj
        """
        max_date = self.data["date"].max()
        start_date = max_date - pd.Timedelta(weeks=windows_week)

        df_filtered = self.data[self.data["date"] > start_date].copy()

        df_weekly = df_filtered.set_index("date").groupby(
            ["index_id", pd.Grouper(freq="W")]
            )["sales"].sum().reset_index()
        
        min_date = df_weekly["date"].min()
        df_weekly["x"] = (df_weekly["date"] - min_date).dt.days /7


        def calculate_slope_vectorized(df_subset):
            """
            Przelicznie nachylenia wektorowo,
            aby doda do rankingu
            """
            df_work = df_subset.copy()
            df_work["xy"] = df_work["x"] * df_work["sales"]
            df_work["xx"] = df_work["x"]**2

            stats = df_work.groupby("index_id").agg(
                n=("sales", "count"),
                sum_x=("x", "sum"),
                sum_y=("sales", "sum"),
                sum_xy=("xy", "sum"),
                sum_xx=("xx", "sum"),
                total_sales=("sales", "sum")
            )

            #wz贸r n * sum(x^2) - (sum(x))^2
            denominator = (stats["n"] * stats["sum_xx"] - stats["sum_x"]**2)
            numerator = (stats["n"] * stats["sum_xy"] - stats["sum_x"] * stats["sum_y"])

            stats["slope"] = np.where(
                denominator != 0,
                numerator / denominator,
                0.0
            )
            return stats

        """df_weekly["xy"] = df_weekly["x"] * df_weekly["sales"]
        df_weekly["xx"] = df_weekly["x"] **2

        stats = df_weekly.groupby("index_id").agg(
            n=("sales", "count"),
            sum_x=("x", "sum"),
            sum_y=("sales", "sum"),
            sum_xy=("xy", "sum"),
            sum_xx=("xx", "sum"),
            total_sales=("sales", "sum")
        )
        stats = stats[stats["total_sales"] >= min_sales]
        #wz贸r n * sum(x^2) - (sum(x))^2
        denominator = (stats["n"] * stats["sum_xx"] - stats["sum_x"]**2)
        numerator = (stats["n"] * stats["sum_xy"] - stats["sum_x"] * stats["sum_y"])

        stats["slope"] = np.where(
            denominator != 0,
            numerator / denominator,
            0.0
        )
        check_date = max_date - pd.Timedelta(weeks=3)
        active_ids = df_filtered[df_filtered["date"]>check_date]["index_id"].unique()
        stats = stats[stats.index.isin(active_ids)]
        #uproszczone velocity liczone slope / rednia sprzeda偶 = % wzrostu
        avg_sales = stats["sum_y"] / stats["n"]
        stats["velocity_proxy"] = np.where(
            avg_sales > 0,
            stats["slope"] / avg_sales,
            0.0
        )"""

        main_stats = calculate_slope_vectorized(df_weekly)
        midpoint_date = start_date + (max_date - start_date) / 2
        df_past = df_weekly[df_weekly["date"] <= midpoint_date]
        df_curr = df_weekly[df_weekly["date"] > midpoint_date]

        stats_past = calculate_slope_vectorized(df_past)[["slope"]].rename(columns={"slope": "slope_past"})
        stats_curr = calculate_slope_vectorized(df_curr)[["slope"]].rename(columns={"slope": "slope_curr"})

        result = main_stats.join(stats_past, how="left").join(stats_curr, how="left")
        result = result.fillna(0)

        result["momentum_val"] = result["slope_curr"] - result["slope_past"]

        conditions =[
            result["momentum_val"] > 0.05,
            result["momentum_val"] < -0.05
        ]

        choices = ["Przyspiesza ", "Zwalnia "]
        result["trend_status"] = np.select(conditions, choices, default="Stabilny ★")
        result = result[result["total_sales"] >= min_sales]

        check_date = max_date - pd.Timedelta(weeks=3)
        active_ids = df_filtered[df_filtered["date"] > check_date]["index_id"].unique()
        result = result[result.index.isin(active_ids)]
        result = result[result["n"] >=min_active_weeks]

        #uproszczone velocity liczone slope / rednia sprzeda偶 = % wzrostu
        avg_sales = result["total_sales"] / result["n"]
        result["velocity_proxy"] = np.where(
            avg_sales > 0,
            result["slope"] / avg_sales,
            0.0
        )
        
        final_df = result[["total_sales","slope", "velocity_proxy", "trend_status"]].reset_index()
        final_df = final_df.sort_values(by="velocity_proxy", ascending=False)
        return final_df